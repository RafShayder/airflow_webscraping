# ğŸš€ Scraper Integratel - ConfiguraciÃ³n con Airflow

## ğŸ“ Estructura del Proyecto

```
scraper-integratel/
â”œâ”€â”€ Dockerfile.airflow              # Dockerfile para Airflow con Chrome/ChromeDriver
â”œâ”€â”€ docker-compose-airflow.yml      # ConfiguraciÃ³n Docker Compose para Airflow
â”œâ”€â”€ requirements.txt                # Dependencias Python
â”œâ”€â”€ env.airflow.example             # Plantilla de variables de entorno
â”œâ”€â”€ dags/                           # DAGs de Airflow
â”‚   â”œâ”€â”€ gde_dag.py                 # DAG para scraper GDE
â”‚   â”œâ”€â”€ dynamic_checklist_dag.py   # DAG para scraper Dynamic Checklist
â”‚   â””â”€â”€ ingest_dag.py              # DAG para ingesta a PostgreSQL
â”œâ”€â”€ proyectos/                      # CÃ³digo del proyecto
â”‚   â””â”€â”€ scraper-integratel/
â”‚       â”œâ”€â”€ GDE.py
â”‚       â”œâ”€â”€ dynamic_checklist.py
â”‚       â”œâ”€â”€ ingest_report.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ src/
â”‚       â””â”€â”€ sql/
â”œâ”€â”€ logs/                           # Logs de Airflow
â”œâ”€â”€ config/                         # ConfiguraciÃ³n de Airflow
â””â”€â”€ plugins/                        # Plugins de Airflow
```

## ğŸ”§ ConfiguraciÃ³n Inicial

### 1. Archivos de Chrome (Para Entornos Sin Internet)

Descarga los siguientes archivos y colÃ³calos en la raÃ­z del proyecto:

```bash
# Chrome 140 para AMD64
wget https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_140.0.6858.0-1_amd64.deb \
  -O chrome_140_amd64.deb

# ChromeDriver para Linux64
wget https://storage.googleapis.com/chrome-for-testing-public/140.0.6858.0/linux64/chromedriver-linux64.zip
```

### 2. Variables de Entorno

```bash
# Copiar plantilla de configuraciÃ³n
cp env.airflow.example .env

# Editar y configurar credenciales
nano .env
```

**Variables importantes a configurar:**
- `USERNAME`: Usuario de Integratel
- `PASSWORD`: ContraseÃ±a de Integratel

### 3. Construir y Levantar Servicios

```bash
# Construir imagen Docker
docker-compose -f docker-compose-airflow.yml build

# Levantar servicios
docker-compose -f docker-compose-airflow.yml up -d
```

## ğŸ“Š Servicios de Airflow

Una vez levantados los servicios, estarÃ¡n disponibles:

- **Airflow Web UI**: http://localhost:8080
  - Usuario: `airflow`
  - ContraseÃ±a: `airflow`
  
- **PostgreSQL**: localhost:5432
  - Base de datos: `airflow`
  - Usuario: `airflow`
  - ContraseÃ±a: `airflow`

- **Prometheus**: http://localhost:9090
- **StatsD Exporter**: http://localhost:9102

## ğŸ¤– DAGs Disponibles

### 1. GDE Scraper (`gde_scraper`)
- **Schedule**: Diario a las 6:00 AM
- **FunciÃ³n**: Descarga el reporte Console GDE Export
- **Output**: `/opt/airflow/proyectos/scraper-integratel/temp/Console_GDE_export*.xlsx`

### 2. Dynamic Checklist Scraper (`dynamic_checklist_scraper`)
- **Schedule**: Diario a las 7:00 AM
- **FunciÃ³n**: Descarga el reporte Dynamic Checklist - Sub PM Query
- **Output**: `/opt/airflow/proyectos/scraper-integratel/temp/DynamicChecklist*.xlsx`

### 3. Ingest Reports (`ingest_reports`)
- **Schedule**: Diario a las 9:00 AM
- **FunciÃ³n**: Ingesta los archivos descargados a PostgreSQL
- **Tablas destino**: 
  - `raw.gde_reports`
  - `raw.dynamic_checklist_tasks`

## ğŸ”„ Flujo de Trabajo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   6:00 AM       â”‚
â”‚  GDE Scraper    â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   7:00 AM       â”‚  â”‚     â”‚   9:00 AM       â”‚
â”‚Dynamic Checklistâ”‚â”€â”€â”¼â”€â”€â”€â”€â–¶â”‚  Ingest Data    â”‚
â”‚    Scraper      â”‚  â”‚     â”‚   to PostgreSQL â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
```

## ğŸ› ï¸ Comandos Ãštiles

### GestiÃ³n de Servicios

```bash
# Ver logs de todos los servicios
docker-compose -f docker-compose-airflow.yml logs -f

# Ver logs de un servicio especÃ­fico
docker-compose -f docker-compose-airflow.yml logs -f airflow-scheduler

# Reiniciar servicios
docker-compose -f docker-compose-airflow.yml restart

# Detener servicios
docker-compose -f docker-compose-airflow.yml down

# Detener y eliminar volÃºmenes
docker-compose -f docker-compose-airflow.yml down -v
```

### EjecuciÃ³n Manual

```bash
# Ejecutar DAG manualmente desde la UI de Airflow
# O desde la lÃ­nea de comandos:

# Entrar al contenedor de Airflow
docker exec -it <container_id> bash

# Ejecutar DAG
airflow dags trigger gde_scraper
airflow dags trigger dynamic_checklist_scraper
airflow dags trigger ingest_reports
```

### Acceso a Archivos

```bash
# Los archivos descargados se encuentran en:
cd proyectos/scraper-integratel/temp/

# Ver archivos descargados
ls -lh proyectos/scraper-integratel/temp/
```

## ğŸ› Troubleshooting

### Problema: No se descargan los archivos

**SoluciÃ³n**: Verificar logs del DAG en la UI de Airflow

```bash
docker-compose -f docker-compose-airflow.yml logs -f airflow-worker
```

### Problema: Error de importaciÃ³n en DAG

**SoluciÃ³n**: Verificar que `PYTHONPATH` estÃ© configurado correctamente

```bash
# Entrar al contenedor
docker exec -it <airflow-worker-container> bash

# Verificar PYTHONPATH
echo $PYTHONPATH

# Verificar que exista el directorio proyectos
ls -la /opt/airflow/proyectos/
```

### Problema: Chrome/ChromeDriver no funciona

**SoluciÃ³n**: Verificar que los archivos estÃ©n en la raÃ­z del proyecto

```bash
ls -lh chrome_140_amd64.deb chromedriver-linux64.zip
```

## ğŸ“ˆ Monitoreo

### MÃ©tricas con Prometheus

Accede a http://localhost:9090 para ver mÃ©tricas de Airflow:

- DuraciÃ³n de tareas
- Tasa de Ã©xito/fallo
- Uso de recursos

### Logs Centralizados

Todos los logs se almacenan en:
```
logs/
â”œâ”€â”€ dag_id=gde_scraper/
â”œâ”€â”€ dag_id=dynamic_checklist_scraper/
â””â”€â”€ dag_id=ingest_reports/
```

## ğŸ”’ Seguridad

### Credenciales

- âš ï¸ **Nunca** commitear el archivo `.env` con credenciales reales
- Usar Airflow Connections para gestionar credenciales en producciÃ³n
- Configurar secrets management (Vault, AWS Secrets Manager, etc.)

### Acceso Web

- Cambiar usuario/contraseÃ±a por defecto de Airflow
- Configurar HTTPS en producciÃ³n
- Implementar autenticaciÃ³n externa (LDAP, OAuth)

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n Airflow](https://airflow.apache.org/docs/)
- [Selenium Documentation](https://www.selenium.dev/documentation/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)

## ğŸ¤ Soporte

Para problemas o consultas, contactar al equipo de desarrollo.

